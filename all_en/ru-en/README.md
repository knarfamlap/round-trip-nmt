# opus-2019-12-05.zip

* dataset: opus
* model: transformer
* pre-processing: normalization + tokenization + BPE
* download: [opus-2019-12-05.zip](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2019-12-05.zip)
* test set translations: [opus-2019-12-05.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2019-12-05.test.txt)
* test set scores: [opus-2019-12-05.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2019-12-05.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newstest2012.ru.en 	| 32.1 	| 0.573 |
| newstest2013.ru.en 	| 25.7 	| 0.516 |
| newstest2014-ruen.ru.en 	| 29.0 	| 0.557 |
| newstest2015-enru.ru.en 	| 27.1 	| 0.537 |
| newstest2016-enru.ru.en 	| 26.3 	| 0.534 |
| newstest2017-enru.ru.en 	| 29.2 	| 0.559 |
| newstest2018-enru.ru.en 	| 26.3 	| 0.533 |
| newstest2019-ruen.ru.en 	| 29.5 	| 0.548 |
| Tatoeba.ru.en 	| 39.5 	| 0.613 |

# opus-2019-12-18.zip

* dataset: opus
* model: transformer-align
* pre-processing: normalization + SentencePiece
* download: [opus-2019-12-18.zip](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2019-12-18.zip)
* test set translations: [opus-2019-12-18.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2019-12-18.test.txt)
* test set scores: [opus-2019-12-18.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2019-12-18.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newstest2012.ru.en 	| 27.4 	| 0.543 |
| newstest2013.ru.en 	| 24.2 	| 0.511 |
| newstest2014-ruen.ru.en 	| 27.4 	| 0.556 |
| newstest2015-enru.ru.en 	| 23.2 	| 0.506 |
| newstest2016-enru.ru.en 	| 24.8 	| 0.526 |
| newstest2017-enru.ru.en 	| 25.4 	| 0.524 |
| newstest2018-enru.ru.en 	| 24.5 	| 0.522 |
| newstest2019-ruen.ru.en 	| 24.4 	| 0.514 |
| Tatoeba.ru.en 	| 56.0 	| 0.696 |

# opus-2020-01-16.zip

* dataset: opus
* model: transformer-align
* pre-processing: normalization + SentencePiece
* download: [opus-2020-01-16.zip](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-01-16.zip)
* test set translations: [opus-2020-01-16.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-01-16.test.txt)
* test set scores: [opus-2020-01-16.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-01-16.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newstest2012.ru.en 	| 35.3 	| 0.606 |
| newstest2013.ru.en 	| 28.2 	| 0.547 |
| newstest2014-ruen.ru.en 	| 32.5 	| 0.595 |
| newstest2015-enru.ru.en 	| 30.7 	| 0.569 |
| newstest2016-enru.ru.en 	| 30.5 	| 0.569 |
| newstest2017-enru.ru.en 	| 33.8 	| 0.596 |
| newstest2018-enru.ru.en 	| 30.0 	| 0.569 |
| newstest2019-ruen.ru.en 	| 32.0 	| 0.581 |
| Tatoeba.ru.en 	| 59.8 	| 0.726 |

# opus-2020-02-11.zip

* dataset: opus
* model: transformer-align
* pre-processing: normalization + SentencePiece
* download: [opus-2020-02-11.zip](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-11.zip)
* test set translations: [opus-2020-02-11.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-11.test.txt)
* test set scores: [opus-2020-02-11.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-11.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newstest2012.ru.en 	| 34.8 	| 0.603 |
| newstest2013.ru.en 	| 28.1 	| 0.546 |
| newstest2014-ruen.ru.en 	| 32.1 	| 0.593 |
| newstest2015-enru.ru.en 	| 30.3 	| 0.567 |
| newstest2016-enru.ru.en 	| 30.1 	| 0.566 |
| newstest2017-enru.ru.en 	| 33.4 	| 0.593 |
| newstest2018-enru.ru.en 	| 29.6 	| 0.566 |
| newstest2019-ruen.ru.en 	| 31.5 	| 0.577 |
| Tatoeba.ru.en 	| 60.8 	| 0.734 |

# opus-2020-02-26.zip

* dataset: opus
* model: transformer-align
* pre-processing: normalization + SentencePiece
* download: [opus-2020-02-26.zip](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-26.zip)
* test set translations: [opus-2020-02-26.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-26.test.txt)
* test set scores: [opus-2020-02-26.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-26.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newstest2012.ru.en 	| 34.8 	| 0.603 |
| newstest2013.ru.en 	| 27.9 	| 0.545 |
| newstest2014-ruen.ru.en 	| 31.9 	| 0.591 |
| newstest2015-enru.ru.en 	| 30.4 	| 0.568 |
| newstest2016-enru.ru.en 	| 30.1 	| 0.565 |
| newstest2017-enru.ru.en 	| 33.4 	| 0.593 |
| newstest2018-enru.ru.en 	| 29.6 	| 0.565 |
| newstest2019-ruen.ru.en 	| 31.4 	| 0.576 |
| Tatoeba.ru.en 	| 61.1 	| 0.736 |

